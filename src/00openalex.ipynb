{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad838ad",
   "metadata": {},
   "source": [
    "# **Retrieving papers from OpenAlex API**\n",
    "\n",
    "This notebook implements a simple pipeline to retrieve papers from the OpenAlex API based on specific criteria. The documentation of the `pyalex` library can be found [here](https://docs.openalex.org/how-to-use-the-api/api-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "70005cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalex import Works, Sources\n",
    "from itertools import chain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d3078ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_id   = \"https://openalex.org/S29331042\"   # Political Analysis\n",
    "lsq_id  = \"https://openalex.org/S48869744\"   # Legislative Studies Quarterly\n",
    "ajps_id = \"https://openalex.org/S90314269\"   # American Journal of Political Science\n",
    "apsr_id = \"https://openalex.org/S176007004\"  # American Political Science Review\n",
    "jpla_id = \"https://openalex.org/S2736728258\" # Journal of Politics in Latin America\n",
    "pp_id   = \"https://openalex.org/S6959732\"    # Party Politics\n",
    "psrm_id = \"https://openalex.org/S2764571748\" # Political Science Research and Methods\n",
    "arps_id = \"https://openalex.org/S8194976\"    # Annual Review of Political Science\n",
    "\n",
    "source_ids = [pa_id, lsq_id, ajps_id, apsr_id, jpla_id, pp_id, psrm_id, arps_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f9a86347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected journals:\n",
      "- Political Analysis\n",
      "- Legislative Studies Quarterly\n",
      "- American Journal of Political Science\n",
      "- American Political Science Review\n",
      "- Journal of Politics in Latin America\n",
      "- Party Politics\n",
      "- Political Science Research and Methods\n",
      "- Annual Review of Political Science\n"
     ]
    }
   ],
   "source": [
    "journals = {}\n",
    "print(\"Selected journals:\")\n",
    "for id_ in source_ids:\n",
    "    source_ = Sources().filter(openalex_id=id_).get()[0]\n",
    "    print(\"-\", source_[\"display_name\"])\n",
    "    journals[id_] = source_[\"display_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "463ff091",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "(\n",
    "  \"text as data\"\n",
    "  OR \"text-as-data\"\n",
    "  OR \"word embeddings\"\n",
    "  OR \"computational text analysis\"\n",
    "  OR \"text mining\"\n",
    "  OR \"natural language processing\"\n",
    "  OR nlp\n",
    ")\n",
    "AND\n",
    "(\n",
    "  legislative\n",
    "  OR legislature\n",
    "  OR parliament\n",
    "  OR parliamentary\n",
    "  OR congressional\n",
    "  OR congress\n",
    "  OR bill\n",
    "  OR bills\n",
    "  OR \"legislative proposal*\"\n",
    "  OR \"legislative text*\"\n",
    "  OR \"political text*\"\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0885da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_abstract(abstract_inverted_index):\n",
    "    \"\"\"\n",
    "    Rebuilds the abstract text from the inverted index.\n",
    "    \"\"\"\n",
    "    if not abstract_inverted_index:\n",
    "        return None\n",
    "\n",
    "    # create a position to word mapping\n",
    "    position_word = {}\n",
    "    for word, positions in abstract_inverted_index.items():\n",
    "        for pos in positions:\n",
    "            position_word[pos] = word\n",
    "\n",
    "    # reconstruct the abstract by ordering words by their positions\n",
    "    return \" \".join(\n",
    "        position_word[pos] for pos in sorted(position_word)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9e3875ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 36 papers from 1 pages for Political Analysis.\n",
      "Retrieved 8 papers from 1 pages for Legislative Studies Quarterly.\n",
      "Retrieved 6 papers from 1 pages for American Journal of Political Science.\n",
      "Retrieved 24 papers from 1 pages for American Political Science Review.\n",
      "Retrieved 1 papers from 1 pages for Journal of Politics in Latin America.\n",
      "Retrieved 6 papers from 1 pages for Party Politics.\n",
      "Retrieved 11 papers from 1 pages for Political Science Research and Methods.\n",
      "Retrieved 5 papers from 1 pages for Annual Review of Political Science.\n"
     ]
    }
   ],
   "source": [
    "works_all = []\n",
    "\n",
    "PER_PAGE = 200\n",
    "MAX_PAGES = 200  # safety cap\n",
    "\n",
    "for journal_id in source_ids:\n",
    "    paginator = (\n",
    "        Works()\n",
    "        .filter(primary_location={\"source\": {\"id\": journal_id}})\n",
    "        .search(query)\n",
    "        .select([\n",
    "            \"id\", \"doi\", \"title\",\n",
    "            \"publication_year\", \"publication_date\",\n",
    "            \"primary_topic\",\n",
    "            \"cited_by_count\",\n",
    "            \"type\",\n",
    "            \"primary_location\",\n",
    "            \"authorships\",\n",
    "            \"abstract_inverted_index\"\n",
    "        ])\n",
    "        .paginate(per_page=PER_PAGE)\n",
    "    )\n",
    "\n",
    "    n_pages = 0 # count pages retrieved\n",
    "    n_papers = 0 # count papers retrieved\n",
    "    \n",
    "    for i, page in enumerate(paginator, start=0):\n",
    "        works_all.extend(page)\n",
    "\n",
    "        # if the next page is empty, break\n",
    "        if len(page) == 0:\n",
    "            break\n",
    "\n",
    "        n_pages += 1\n",
    "        n_papers += len(page)\n",
    "\n",
    "        # if we reach the max pages, break\n",
    "        if i >= MAX_PAGES:\n",
    "            break\n",
    "        \n",
    "    print(f\"Retrieved {n_papers} papers from {n_pages} pages for {journals[journal_id]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8e246133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a way of iterating the paginator object directly\n",
    "# for record in chain(paginator):\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "88fc77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for work in works_all:\n",
    "    work[\"abstract\"] = reconstruct_abstract(work.get(\"abstract_inverted_index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3681a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total works found: 97\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total works found: {len(works_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "625abea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(works_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ccb74cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column primary_topic is a dictionary; we can expand it into multiple columns\n",
    "primary_topics = pd.json_normalize(df['primary_topic'])\n",
    "primary_locations = pd.json_normalize(df['primary_location'])\n",
    "authorships = pd.json_normalize(df['authorships'])\n",
    "\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df.drop(columns=['primary_topic', 'primary_location', 'authorships', 'abstract_inverted_index']),\n",
    "        primary_topics.add_prefix('primary_topic.'), \n",
    "        primary_locations.add_prefix('primary_location.'), \n",
    "        authorships.add_prefix('authorships.')\n",
    "        ], \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "83dfccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorships_0 = pd.json_normalize(df[\"authorships.0\"])\n",
    "authorships_1 = pd.json_normalize(df[\"authorships.1\"])\n",
    "authorships_2 = pd.json_normalize(df[\"authorships.2\"])\n",
    "authorships_3 = pd.json_normalize(df[\"authorships.3\"])\n",
    "authorships_4 = pd.json_normalize(df[\"authorships.4\"])\n",
    "authorships_5 = pd.json_normalize(df[\"authorships.5\"])\n",
    "authorships_6 = pd.json_normalize(df[\"authorships.6\"])\n",
    "\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df.drop(columns=[\n",
    "            'authorships.0', 'authorships.1', 'authorships.2', \n",
    "            'authorships.3', 'authorships.4', 'authorships.5', \n",
    "            'authorships.6']),\n",
    "        authorships_0.add_prefix('authorships.0.'),\n",
    "        authorships_1.add_prefix('authorships.1.'),\n",
    "        authorships_2.add_prefix('authorships.2.'),\n",
    "        authorships_3.add_prefix('authorships.3.'),\n",
    "        authorships_4.add_prefix('authorships.4.'),\n",
    "        authorships_5.add_prefix('authorships.5.'),\n",
    "        authorships_6.add_prefix('authorships.6.')\n",
    "    ],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6237d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flt = df[[\n",
    "    \"id\", \n",
    "    \"doi\", \n",
    "    \"title\", \n",
    "    \"publication_year\", \n",
    "    \"publication_date\", \n",
    "    \"cited_by_count\", \n",
    "    \"type\", \n",
    "    \"abstract\",\n",
    "    \"primary_topic.display_name\", \n",
    "    \"primary_topic.subfield.display_name\",\n",
    "    \"primary_location.source.display_name\",\n",
    "    \"primary_location.is_oa\",\n",
    "    \"authorships.0.author.display_name\",\n",
    "    \"authorships.1.author.display_name\",\n",
    "    \"authorships.2.author.display_name\",\n",
    "    \"authorships.3.author.display_name\",\n",
    "    \"authorships.4.author.display_name\",\n",
    "    \"authorships.5.author.display_name\",\n",
    "    \"authorships.6.author.display_name\"\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5e112e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Local\\Temp\\ipykernel_16408\\942066451.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_flt.sort_values(by=[\"cited_by_count\"], ascending=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_flt.sort_values(by=[\"cited_by_count\"], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9ec4c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flt.to_excel(\"../data/openalex_systematic_review.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
